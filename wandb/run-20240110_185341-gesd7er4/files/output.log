
  0%|                                                                                                                             | 0/200 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.





























 25%|█████████████████████████████                                                                                       | 50/200 [01:01<03:02,  1.22s/it]



























 50%|█████████████████████████████████████████████████████████▍                                                          | 99/200 [01:56<01:40,  1.01it/s]





























 74%|█████████████████████████████████████████████████████████████████████████████████████▋                             | 149/200 [02:53<00:58,  1.15s/it]






























100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [03:54<00:00,  1.12s/it]
{'loss': 0.3259, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.06}

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [03:54<00:00,  1.17s/it]